{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Classificasion Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Problem Statement\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "Team 8 is challenged with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data. This will be achieved with the steps outlined below:\n",
    "\n",
    "- 1. analyse the supplied data;\n",
    "- 2. identify potential errors in the data and clean the existing data set;\n",
    "- 3. determine if additional features can be added to enrich the data set;\n",
    "- 4. build a model that is capable of forecasting the three hourly demand shortfalls;\n",
    "- 5. evaluate the accuracy of the best machine learning model;\n",
    "- 6. determine what features were most important in the model’s prediction decision, and\n",
    "- 7. explain the inner working of the model to a non-technical audience.\n",
    "\n",
    "Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing modules for data science and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 180 # Quality of all figures in notebook\n",
    "# NLP Libraries\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from os import path\n",
    "from PIL import Image\n",
    "#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import pos_tag\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('https://github.com/Gabe-Maja/SA-Language-Identification_Classification-Hackathon/blob/main/train_set.csv?raw=true')\n",
    "\n",
    "df_test = pd.read_csv('https://github.com/Gabe-Maja/SA-Language-Identification_Classification-Hackathon/blob/main/test_set.csv?raw=true')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nso</td>\n",
       "      <td>dinyakišišo tše tša go dirwa gabedi ka ngwaga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tsn</td>\n",
       "      <td>kgetse nngwe le nngwe e e sa faposiwang mo tsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ven</td>\n",
       "      <td>mbadelo dze dza laelwa dzi do kwama mahatulele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nso</td>\n",
       "      <td>maloko a dikhuduthamaga a ikarabela mongwe le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tsn</td>\n",
       "      <td>fa le dirisiwa lebone le tshwanetse go bontsha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nbl</td>\n",
       "      <td>lapho inarha yangeqadi ingenwe ngokungasimthet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ven</td>\n",
       "      <td>yo dovha hafhu ya khwaṱhisedza uri hu vhe na m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zul</td>\n",
       "      <td>i-tip-offs anonymous wusizo locingo oluzimele ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ssw</td>\n",
       "      <td>tekulima lokufaka ekhatsi yonkhe imisebenti ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zul</td>\n",
       "      <td>noma yiliphi ilungu lombutho wezokuvikela elin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nso</td>\n",
       "      <td>c a fa tumelelo ya go hloma go aga goba go bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tso</td>\n",
       "      <td>migingiriko ya cbnrm hinkwayo yi katsa ku tumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zul</td>\n",
       "      <td>amalungu nabangabasebenzi banelungelo lokwenza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sot</td>\n",
       "      <td>ka ho mengwa lefapheng la lona diprofeshenale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nbl</td>\n",
       "      <td>isitifikhethi somtjhado esingakarhunyezwa namk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lang_id                                               text\n",
       "0      xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1      xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2      eng  the province of kwazulu-natal department of tr...\n",
       "3      nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4      ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "5      nso  dinyakišišo tše tša go dirwa gabedi ka ngwaga ...\n",
       "6      tsn  kgetse nngwe le nngwe e e sa faposiwang mo tsh...\n",
       "7      ven  mbadelo dze dza laelwa dzi do kwama mahatulele...\n",
       "8      nso  maloko a dikhuduthamaga a ikarabela mongwe le ...\n",
       "9      tsn  fa le dirisiwa lebone le tshwanetse go bontsha...\n",
       "10     nbl  lapho inarha yangeqadi ingenwe ngokungasimthet...\n",
       "11     ven  yo dovha hafhu ya khwaṱhisedza uri hu vhe na m...\n",
       "12     zul  i-tip-offs anonymous wusizo locingo oluzimele ...\n",
       "13     ssw  tekulima lokufaka ekhatsi yonkhe imisebenti ye...\n",
       "14     zul  noma yiliphi ilungu lombutho wezokuvikela elin...\n",
       "15     nso  c a fa tumelelo ya go hloma go aga goba go bea...\n",
       "16     tso  migingiriko ya cbnrm hinkwayo yi katsa ku tumb...\n",
       "17     zul  amalungu nabangabasebenzi banelungelo lokwenza...\n",
       "18     sot  ka ho mengwa lefapheng la lona diprofeshenale ...\n",
       "19     nbl  isitifikhethi somtjhado esingakarhunyezwa namk..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0543a9ef-4468-4db7-bfb4-8e98cb270b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ke feela dilense tše hlakilego, tša pono e tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>&lt;fn&gt;(762010101403 AM) 1495 Final Gems Birthing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ntjhafatso ya konteraka ya mosebetsi: Etsa bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>u-GEMS uhlinzeka ngezinzuzo zemithi yezifo ezi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>So, on occasion, are statistics misused.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Janewari la ngwaga ofe kapa, dikholego tša gag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Ntirho wa mfumo : ku aka swikolo swo ringana n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Kl.(3) e emetswe ke k. 13 ya Molaotheo Tlhabol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Tshabo le ho se sireletsehe hoo ho ile ha baka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Loko u nga ri na ntiyiso wa leswaku xiphiqo xa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>lokuthabatha inxaxheba kwiintshukumo neeprogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Icandelwana (2) lithathelwe indawo licandelo 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>LaMatsebula Yebo Mtilankhatsa, uva kahle. Wona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Enige persoon wat 'n bepaling van hierdie vero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Minisi.a' zwi amba Minisi.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                               text\n",
       "0       1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1       2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2       3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3       4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4       5                      Winste op buitelandse valuta.\n",
       "5       6  Ke feela dilense tše hlakilego, tša pono e tee...\n",
       "6       7  <fn>(762010101403 AM) 1495 Final Gems Birthing...\n",
       "7       8  Ntjhafatso ya konteraka ya mosebetsi: Etsa bon...\n",
       "8       9  u-GEMS uhlinzeka ngezinzuzo zemithi yezifo ezi...\n",
       "9      10           So, on occasion, are statistics misused.\n",
       "10     11  Janewari la ngwaga ofe kapa, dikholego tša gag...\n",
       "11     12  Ntirho wa mfumo : ku aka swikolo swo ringana n...\n",
       "12     13  Kl.(3) e emetswe ke k. 13 ya Molaotheo Tlhabol...\n",
       "13     14  Tshabo le ho se sireletsehe hoo ho ile ha baka...\n",
       "14     15  Loko u nga ri na ntiyiso wa leswaku xiphiqo xa...\n",
       "15     16  lokuthabatha inxaxheba kwiintshukumo neeprogra...\n",
       "16     17  Icandelwana (2) lithathelwe indawo licandelo 9...\n",
       "17     18  LaMatsebula Yebo Mtilankhatsa, uva kahle. Wona...\n",
       "18     19  Enige persoon wat 'n bepaling van hierdie vero...\n",
       "19     20                         Minisi.a' zwi amba Minisi."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3edc2877-9ad7-4f48-a9b2-c3fb57907ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64cc48fa-79f5-4827-90d1-aa7ce310c90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5682, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c4eaf13-8906-495c-8823-a2d363316c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# train info\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "885ba9ad-c5ec-49e2-97ca-138365e764bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5682 entries, 0 to 5681\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   index   5682 non-null   int64 \n",
      " 1   text    5682 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 88.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# test info\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fb74182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in train dataset\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dd6ee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in test dataset\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2dac9ee1-f664-415a-87ba-96899714aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6dfe3046-03f6-47c3-964c-850ed8292d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sparse to train the model using both representations.\n",
    "import scipy.sparse\n",
    "\n",
    "# Defining the features as well as the label\n",
    "X = df_train['text']\n",
    "y = df_train['lang_id']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9593c528-ea66-46c9-ae36-a25a99647c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "de51df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the previously defined features and label of your dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dd10cd6-0ddb-419c-b91d-4a4e01f9c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of all the models to train\n",
    "algs = [LogisticRegression(random_state = 5), SVC(kernel = 'linear', random_state = 5), SVC(kernel = 'rbf', random_state = 5)\n",
    "        ,MultinomialNB(), KNeighborsClassifier(), DecisionTreeClassifier(max_depth=6),RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe172bc0-4091-48ff-aadc-a2b3b19c126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=5)\n",
      "[[580   0   0   0   0   2   0   0   0   1   0]\n",
      " [  0 615   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 576   0   0   0   0   0   0   1   6]\n",
      " [  0   0   0 622   1   0   2   0   0   0   0]\n",
      " [  0   0   0   0 618   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 583   0   0   0   0   1]\n",
      " [  1   0   0   1   3   0 592   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0 561   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 634   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0 602   6]\n",
      " [  0   1   8   0   0   1   0   0   0   3 577]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.99      1.00       583\n",
      "         eng       1.00      1.00      1.00       615\n",
      "         nbl       0.98      0.99      0.99       583\n",
      "         nso       1.00      1.00      1.00       625\n",
      "         sot       0.99      1.00      1.00       618\n",
      "         ssw       0.99      1.00      1.00       584\n",
      "         tsn       1.00      0.99      0.99       598\n",
      "         tso       1.00      1.00      1.00       561\n",
      "         ven       1.00      1.00      1.00       634\n",
      "         xho       0.99      0.99      0.99       609\n",
      "         zul       0.98      0.98      0.98       590\n",
      "\n",
      "    accuracy                           0.99      6600\n",
      "   macro avg       0.99      0.99      0.99      6600\n",
      "weighted avg       0.99      0.99      0.99      6600\n",
      "\n",
      "F1_score:  0.994\n",
      "-------------------------------------------------------\n",
      "SVC(kernel='linear', random_state=5)\n",
      "[[578   0   0   0   0   3   0   0   0   2   0]\n",
      " [  0 614   0   0   0   0   0   0   0   0   1]\n",
      " [  1   0 574   0   0   0   0   0   0   1   7]\n",
      " [  0   0   1 621   1   0   2   0   0   0   0]\n",
      " [  0   0   0   0 618   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 583   0   0   0   0   1]\n",
      " [  1   0   0   1   3   0 592   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0 561   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 634   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0 602   6]\n",
      " [  0   1   6   0   0   1   0   0   0   2 580]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.99      0.99       583\n",
      "         eng       1.00      1.00      1.00       615\n",
      "         nbl       0.99      0.98      0.99       583\n",
      "         nso       1.00      0.99      1.00       625\n",
      "         sot       0.99      1.00      1.00       618\n",
      "         ssw       0.99      1.00      1.00       584\n",
      "         tsn       1.00      0.99      0.99       598\n",
      "         tso       1.00      1.00      1.00       561\n",
      "         ven       1.00      1.00      1.00       634\n",
      "         xho       0.99      0.99      0.99       609\n",
      "         zul       0.97      0.98      0.98       590\n",
      "\n",
      "    accuracy                           0.99      6600\n",
      "   macro avg       0.99      0.99      0.99      6600\n",
      "weighted avg       0.99      0.99      0.99      6600\n",
      "\n",
      "F1_score:  0.993\n",
      "-------------------------------------------------------\n",
      "SVC(random_state=5)\n",
      "[[577   1   0   0   0   2   0   0   0   3   0]\n",
      " [  0 613   0   0   0   0   0   0   0   2   0]\n",
      " [  1   0 568   0   0   0   0   0   0   3  11]\n",
      " [  0   0   0 621   1   0   2   0   0   1   0]\n",
      " [  0   0   0   0 617   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0 582   0   0   0   0   2]\n",
      " [  1   0   0   2   3   0 591   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0 561   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 634   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0 603   4]\n",
      " [  0   1   8   0   0   0   0   0   0   4 577]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.99      0.99       583\n",
      "         eng       1.00      1.00      1.00       615\n",
      "         nbl       0.98      0.97      0.98       583\n",
      "         nso       1.00      0.99      1.00       625\n",
      "         sot       0.99      1.00      1.00       618\n",
      "         ssw       1.00      1.00      1.00       584\n",
      "         tsn       1.00      0.99      0.99       598\n",
      "         tso       1.00      1.00      1.00       561\n",
      "         ven       1.00      1.00      1.00       634\n",
      "         xho       0.98      0.99      0.98       609\n",
      "         zul       0.97      0.98      0.97       590\n",
      "\n",
      "    accuracy                           0.99      6600\n",
      "   macro avg       0.99      0.99      0.99      6600\n",
      "weighted avg       0.99      0.99      0.99      6600\n",
      "\n",
      "F1_score:  0.992\n",
      "-------------------------------------------------------\n",
      "MultinomialNB()\n",
      "[[583   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 615   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 583   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 624   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0 618   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 584   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0 597   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 561   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 634   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0 607   1]\n",
      " [  0   1   2   0   0   0   0   0   0   0 587]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       583\n",
      "         eng       1.00      1.00      1.00       615\n",
      "         nbl       0.99      1.00      1.00       583\n",
      "         nso       1.00      1.00      1.00       625\n",
      "         sot       1.00      1.00      1.00       618\n",
      "         ssw       1.00      1.00      1.00       584\n",
      "         tsn       1.00      1.00      1.00       598\n",
      "         tso       1.00      1.00      1.00       561\n",
      "         ven       1.00      1.00      1.00       634\n",
      "         xho       1.00      1.00      1.00       609\n",
      "         zul       1.00      0.99      1.00       590\n",
      "\n",
      "    accuracy                           1.00      6600\n",
      "   macro avg       1.00      1.00      1.00      6600\n",
      "weighted avg       1.00      1.00      1.00      6600\n",
      "\n",
      "F1_score:  0.999\n",
      "-------------------------------------------------------\n",
      "KNeighborsClassifier()\n",
      "[[578   0   2   0   0   2   0   0   0   1   0]\n",
      " [  1 610   0   0   0   0   0   0   0   0   4]\n",
      " [  1   0 529   0   0   5   0   0   0   3  45]\n",
      " [  0   0   3 570   4   0  47   0   0   1   0]\n",
      " [  0   0   4   3 589   0  22   0   0   0   0]\n",
      " [  0   0  29   0   0 515   0   0   0   2  38]\n",
      " [  1   0   3  32   7   0 554   0   1   0   0]\n",
      " [  0   0   2   0   0   1   0 557   1   0   0]\n",
      " [  0   0   4   0   0   1   0   0 629   0   0]\n",
      " [  0   0  90   0   0  11   0   0   0 456  52]\n",
      " [  0   0  54   0   0  16   0   0   0  17 503]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       0.99      0.99      0.99       583\n",
      "         eng       1.00      0.99      1.00       615\n",
      "         nbl       0.73      0.91      0.81       583\n",
      "         nso       0.94      0.91      0.93       625\n",
      "         sot       0.98      0.95      0.97       618\n",
      "         ssw       0.93      0.88      0.91       584\n",
      "         tsn       0.89      0.93      0.91       598\n",
      "         tso       1.00      0.99      1.00       561\n",
      "         ven       1.00      0.99      0.99       634\n",
      "         xho       0.95      0.75      0.84       609\n",
      "         zul       0.78      0.85      0.82       590\n",
      "\n",
      "    accuracy                           0.92      6600\n",
      "   macro avg       0.93      0.92      0.92      6600\n",
      "weighted avg       0.93      0.92      0.92      6600\n",
      "\n",
      "F1_score:  0.924\n",
      "-------------------------------------------------------\n",
      "DecisionTreeClassifier(max_depth=6)\n",
      "[[544   0   0   0   0   0   0   0   0   0  39]\n",
      " [  0 569   0   0   0   0   0   0   0   0  46]\n",
      " [  1   0   1   0   1   0   0  12   0   0 568]\n",
      " [  0   0   0 463   0   0 113   0   0   0  49]\n",
      " [  0   0   0   0 563   0   0   0   0   0  55]\n",
      " [  0   0   0   0   0   0   0  20  10   0 554]\n",
      " [  0   1   0   1   0   0 541   0   0   0  55]\n",
      " [  0   0   0   0   0   0   0 515  29   0  17]\n",
      " [  0   0   0   0  24   0   0   3 449   0 158]\n",
      " [  0   1   1   0   0   0   0   5   0   0 602]\n",
      " [  0   2   0   0   0   0   0  10   0   0 578]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.93      0.96       583\n",
      "         eng       0.99      0.93      0.96       615\n",
      "         nbl       0.50      0.00      0.00       583\n",
      "         nso       1.00      0.74      0.85       625\n",
      "         sot       0.96      0.91      0.93       618\n",
      "         ssw       0.00      0.00      0.00       584\n",
      "         tsn       0.83      0.90      0.86       598\n",
      "         tso       0.91      0.92      0.91       561\n",
      "         ven       0.92      0.71      0.80       634\n",
      "         xho       0.00      0.00      0.00       609\n",
      "         zul       0.21      0.98      0.35       590\n",
      "\n",
      "    accuracy                           0.64      6600\n",
      "   macro avg       0.67      0.64      0.60      6600\n",
      "weighted avg       0.67      0.64      0.61      6600\n",
      "\n",
      "F1_score:  0.607\n",
      "-------------------------------------------------------\n",
      "RandomForestClassifier()\n",
      "[[582   0   0   0   0   0   0   0   0   0   1]\n",
      " [  0 615   0   0   0   0   0   0   0   0   0]\n",
      " [  1   1 550   0   0   2   0   0   0   7  22]\n",
      " [  0   0   0 622   1   0   2   0   0   0   0]\n",
      " [  0   0   0   1 617   0   0   0   0   0   0]\n",
      " [  0   1   1   0   0 562   0   0   0   0  20]\n",
      " [  1   0   0   1   1   0 595   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 561   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 634   0   0]\n",
      " [  0   0   5   0   0   1   0   0   0 590  13]\n",
      " [  0   1   7   0   0   3   0   0   0  12 567]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       583\n",
      "         eng       1.00      1.00      1.00       615\n",
      "         nbl       0.98      0.94      0.96       583\n",
      "         nso       1.00      1.00      1.00       625\n",
      "         sot       1.00      1.00      1.00       618\n",
      "         ssw       0.99      0.96      0.98       584\n",
      "         tsn       1.00      0.99      1.00       598\n",
      "         tso       1.00      1.00      1.00       561\n",
      "         ven       1.00      1.00      1.00       634\n",
      "         xho       0.97      0.97      0.97       609\n",
      "         zul       0.91      0.96      0.93       590\n",
      "\n",
      "    accuracy                           0.98      6600\n",
      "   macro avg       0.98      0.98      0.98      6600\n",
      "weighted avg       0.98      0.98      0.98      6600\n",
      "\n",
      "F1_score:  0.984\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Fitting models onto the training data and predicting.\n",
    "for i in range(0, len(algs)):\n",
    "    text_clf = Pipeline([('clf', algs[i])])\n",
    "    ##lowercase = True,stop_words='english', ngram_range=(1, 2), analyzer='word',max_df = 0.8\n",
    "    text_clf.fit(X_train, y_train)  \n",
    "    predictions = text_clf.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print(algs[i])\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print('F1_score: ',round(metrics.f1_score(y_test,predictions, average = 'weighted'),3))\n",
    "    print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1f72dac6-ef67-4ae6-9dd1-2b4ba6c86bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.3)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=0.3)\n",
    "clf.fit(vect.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e50e6cb3-16e8-418c-bb84-4a2da76f0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9eefece2-3be9-46a5-a63c-abdc9708a130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       583\n",
      "         eng       1.00      1.00      1.00       615\n",
      "         nbl       1.00      1.00      1.00       583\n",
      "         nso       1.00      1.00      1.00       625\n",
      "         sot       1.00      1.00      1.00       618\n",
      "         ssw       1.00      1.00      1.00       584\n",
      "         tsn       1.00      1.00      1.00       598\n",
      "         tso       1.00      1.00      1.00       561\n",
      "         ven       1.00      1.00      1.00       634\n",
      "         xho       1.00      1.00      1.00       609\n",
      "         zul       1.00      1.00      1.00       590\n",
      "\n",
      "    accuracy                           1.00      6600\n",
      "   macro avg       1.00      1.00      1.00      6600\n",
      "weighted avg       1.00      1.00      1.00      6600\n",
      "\n",
      "F1_score:  0.9993938107\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('F1_score: ',round(metrics.f1_score(y_test,y_pred, average = 'weighted'),10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e43598-d9f9-4f65-bc45-8cb87eab5131",
   "metadata": {},
   "source": [
    "## Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5c37f610-f76b-4831-bff5-4f7a9d548dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Kaggle = df_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "298ca268-de4f-4247-b796-959637c8beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_pred = clf.predict(vect.transform(X_Kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "facf2c2e-1e74-4446-a069-57cdb01e607f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     tsn\n",
       "1      2     nbl\n",
       "2      3     ven\n",
       "3      4     ssw\n",
       "4      5     afr"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(data=df_test['index'], columns=['index'])\n",
    "pred_df.insert(1, 'lang_id', kaggle_pred, allow_duplicates=False)\n",
    "\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3cbc8e4a-117a-4841-b4dc-77b2aa8e1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(path_or_buf='Gabe_MultiNB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to: clean the dataset, and possibly create new features - as identified in the EDA phase. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        MultinomialNB\n",
       "\u001b[1;31mString form:\u001b[0m MultinomialNB()\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\gabem\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Naive Bayes classifier for multinomial models\n",
       "\n",
       "The multinomial Naive Bayes classifier is suitable for classification with\n",
       "discrete features (e.g., word counts for text classification). The\n",
       "multinomial distribution normally requires integer feature counts. However,\n",
       "in practice, fractional counts such as tf-idf may also work.\n",
       "\n",
       "Read more in the :ref:`User Guide <multinomial_naive_bayes>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "alpha : float, default=1.0\n",
       "    Additive (Laplace/Lidstone) smoothing parameter\n",
       "    (0 for no smoothing).\n",
       "\n",
       "fit_prior : bool, default=True\n",
       "    Whether to learn class prior probabilities or not.\n",
       "    If false, a uniform prior will be used.\n",
       "\n",
       "class_prior : array-like of shape (n_classes,), default=None\n",
       "    Prior probabilities of the classes. If specified the priors are not\n",
       "    adjusted according to the data.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "class_count_ : ndarray of shape (n_classes,)\n",
       "    Number of samples encountered for each class during fitting. This\n",
       "    value is weighted by the sample weight when provided.\n",
       "\n",
       "class_log_prior_ : ndarray of shape (n_classes, )\n",
       "    Smoothed empirical log probability for each class.\n",
       "\n",
       "classes_ : ndarray of shape (n_classes,)\n",
       "    Class labels known to the classifier\n",
       "\n",
       "coef_ : ndarray of shape (n_classes, n_features)\n",
       "    Mirrors ``feature_log_prob_`` for interpreting `MultinomialNB`\n",
       "    as a linear model.\n",
       "\n",
       "    .. deprecated:: 0.24\n",
       "        ``coef_`` is deprecated in 0.24 and will be removed in 1.1\n",
       "        (renaming of 0.26).\n",
       "\n",
       "feature_count_ : ndarray of shape (n_classes, n_features)\n",
       "    Number of samples encountered for each (class, feature)\n",
       "    during fitting. This value is weighted by the sample weight when\n",
       "    provided.\n",
       "\n",
       "feature_log_prob_ : ndarray of shape (n_classes, n_features)\n",
       "    Empirical log probability of features\n",
       "    given a class, ``P(x_i|y)``.\n",
       "\n",
       "intercept_ : ndarray of shape (n_classes,)\n",
       "    Mirrors ``class_log_prior_`` for interpreting `MultinomialNB`\n",
       "    as a linear model.\n",
       "\n",
       "    .. deprecated:: 0.24\n",
       "        ``intercept_`` is deprecated in 0.24 and will be removed in 1.1\n",
       "        (renaming of 0.26).\n",
       "\n",
       "n_features_ : int\n",
       "    Number of features of each sample.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> rng = np.random.RandomState(1)\n",
       ">>> X = rng.randint(5, size=(6, 100))\n",
       ">>> y = np.array([1, 2, 3, 4, 5, 6])\n",
       ">>> from sklearn.naive_bayes import MultinomialNB\n",
       ">>> clf = MultinomialNB()\n",
       ">>> clf.fit(X, y)\n",
       "MultinomialNB()\n",
       ">>> print(clf.predict(X[2:3]))\n",
       "[3]\n",
       "\n",
       "Notes\n",
       "-----\n",
       "For the rationale behind the names `coef_` and `intercept_`, i.e.\n",
       "naive Bayes as a linear classifier, see J. Rennie et al. (2003),\n",
       "Tackling the poor assumptions of naive Bayes text classifiers, ICML.\n",
       "\n",
       "References\n",
       "----------\n",
       "C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to\n",
       "Information Retrieval. Cambridge University Press, pp. 234-265.\n",
       "https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eea17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59692724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineer existing features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to create one or more regression models that are able to accurately predict the thee hour load shortfall. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets and features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one or more ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
